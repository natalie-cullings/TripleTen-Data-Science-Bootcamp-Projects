{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Objective\n",
    "\n",
    "The Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra.\n",
    "\n",
    "Using monthly behaviorial data about subscribers who have already switched to the new plans, the objective of this project is to develop a machine learning model to help pick the right plan for legacy plan users.\n",
    "\n",
    "I will optimize models suitable for a classification task with the goal of producing the highest possible accuracy score for each model. It must have an accuracy score of at least 75%.\n",
    "\n",
    "# Data description\n",
    "\n",
    "Every observation in the dataset contains monthly behavior information about one user. The information given is as follows:\n",
    "- сalls — number of calls\n",
    "- minutes — total call duration in minutes\n",
    "- messages — number of text messages\n",
    "- mb_used — Internet traffic used in MB\n",
    "- is_ultra — plan for the current month (Ultra - 1, Smart - 0)\n",
    "\n",
    "# Project Plan\n",
    "- Load and inspect the data.\n",
    "- Split the data into train, validate, and test sets then specify features and a target for each.\n",
    "- Train the Decision Tree Classifier, Random Forest Classifier, and Logistic Regression models using the training data set.\n",
    "- Optimize the accuracy score of the validation data set for each model.\n",
    "- Assess the accuracy score of the testing data set for the best instance of each model.\n",
    "- Assess the best model to use in order to help Megaline pick the right plan for its legacy plan users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      calls  minutes  messages   mb_used  is_ultra\n",
      "2024   27.0   147.66      39.0   7545.04         0\n",
      "1822  115.0   679.27       1.0  28668.40         1\n",
      "3095   63.0   409.35       0.0   4300.48         1\n",
      "1732   34.0   217.52      23.0  14040.66         0\n",
      "1768   70.0   497.55      66.0  24918.49         0\n",
      "1714   56.0   324.99      78.0  10977.57         0\n",
      "3053   35.0   219.89      40.0  13664.23         0\n",
      "764    66.0   488.95      46.0  17383.22         0\n",
      "946    33.0   247.29       0.0  30996.30         1\n",
      "720     1.0    14.91      55.0  23828.60         0\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "\n",
      "It's safe to convert df['calls'] to int: True\n",
      "It's safe to convert df['messages'] to int: True\n"
     ]
    }
   ],
   "source": [
    "# read csv to dataframe\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "\n",
    "# preview data\n",
    "print(f\"{df.sample(10)}\\n\")\n",
    "\n",
    "# get info about the data\n",
    "df.info()\n",
    "\n",
    "# validate that it's safe to convert calls and messages to int without losing data\n",
    "print(\"\\nIt's safe to convert df['calls'] to int:\",np.array_equal(df['calls'],df['calls'].astype(int)))\n",
    "print(\"It's safe to convert df['messages'] to int:\", np.array_equal(df['messages'],df['messages'].astype(int)))\n",
    "\n",
    "# convert calls and messages to int\n",
    "df['calls'] = df['calls'].astype(int)\n",
    "df['messages'] = df['messages'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is as expected for the most part except that it's unnecessary for the 'calls' and 'messages' columns to be float data types so I converted them to int data types after validating that it was safe to do so (no data would be lost)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train, validate, and test sets then specify features and a target for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the source data into a training set and validation/testing set\n",
    "df_train, df_test_valid = train_test_split(df, test_size=0.4, random_state=12345)\n",
    "\n",
    "# split the validation/testing df into a separate validation set and testing set\n",
    "df_test, df_valid = train_test_split(df_test_valid, test_size=0.5, random_state=12345)\n",
    "\n",
    "# designate a list of features and a target in separate variables for df_train\n",
    "train_features = df_train.drop(['is_ultra'], axis=1)\n",
    "train_target = df_train['is_ultra']\n",
    "\n",
    "# designate a list of features and a target in separate variables for df_test\n",
    "test_features = df_test.drop(['is_ultra'], axis=1)\n",
    "test_target = df_test['is_ultra']\n",
    "\n",
    "# designate a list of features and a target in separate variables for df_valid\n",
    "valid_features = df_valid.drop(['is_ultra'], axis=1)\n",
    "valid_target = df_valid['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set doesn't exist yet so the source data (df) has to be split into three parts: training, validation, and test. The sizes of the validation set and test set are usually equal so that gives us source data split in a 3:1:1 ratio.\n",
    "\n",
    "Consequently, I split the source data into two parts: 60% training data and 40% validation/testing data.\n",
    "Next, I split the validation/testing data in two equal 50% parts.\n",
    "Overall, this leaves me with a 3:1:1 ratio as desired with a majority of the data (a sufficient amount) available to train my models with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the Decision Tree Classifier Model for the Validation Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model: 0.7993779160186625\n",
      "Max_depth of best model: 7\n",
      "\n",
      "Accuracy of the model (training data): 0.8558091286307054\n"
     ]
    }
   ],
   "source": [
    "# initialize values for the best_model and best_result to use in the subsequent loop\n",
    "best_model = None\n",
    "best_result = 0\n",
    "\n",
    "# tune the hyperparameters of the Decision Tree Classifier model to find the best model\n",
    "for depth in range(1, 9): # loop through values 1-8 for the max_depth= parameter\n",
    "    model_dt = DecisionTreeClassifier( # ititialize the Decision Tree Classifier Model\n",
    "        random_state=12345, \n",
    "        max_depth=depth) \n",
    "    model_dt.fit(train_features, train_target) # train the model\n",
    "    valid_result = model_dt.score(valid_features, valid_target) # calculate the accuracy score for the validation data\n",
    "    train_result = model_dt.score(train_features, train_target) # calculate the accuracy score for the training data\n",
    "    if valid_result > best_result: # store the best model, its best accuracy score, and the max_depth parameter value for its best score in variables\n",
    "        best_model = model_dt\n",
    "        best_result = valid_result\n",
    "        best_depth = depth\n",
    "        best_train_result = train_result # also store the training data's accuracy score for the best model\n",
    "\n",
    "# print the accuracy score of the best model and the value of its max_depth parameter\n",
    "print(\"Accuracy of the best model:\", best_result)\n",
    "print(\"Max_depth of best model:\", best_depth)\n",
    "\n",
    "# print the accuracy score of the best model for the training data as well\n",
    "print(\"\\nAccuracy of the model (training data):\", best_train_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is overfitted with a max_depth of 7 and a training set accuracy score that's notably higher than the accuracy score of the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the Random Forest Classifier Model for the Validation Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model on the validation set (n_estimators = 6): 0.7807153965785381\n",
      "Accuracy of the best model on the training set: 0.966804979253112\n"
     ]
    }
   ],
   "source": [
    "# initialize values for the best_model and best_result to use in the subsequent loop\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "\n",
    "# tune the hyperparameters of the Random Forest Classifier model to find the best model\n",
    "for est in range(1, 10): # choose hyperparameter range\n",
    "    model_rf = RandomForestClassifier( # ititialize the Random Forest Classifier model\n",
    "        random_state=54321, \n",
    "        n_estimators=est\n",
    "    ) # set number of trees\n",
    "    model_rf.fit(train_features, train_target) # train model on training set\n",
    "    score = model_rf.score(valid_features, valid_target) # calculate accuracy score on validation set\n",
    "    score_train = model_rf.score(train_features, train_target) # calculate accuracy score on the training set\n",
    "    if score > best_score:\n",
    "        best_score = score # save best accuracy score on validation set\n",
    "        best_est = est # save number of estimators corresponding to best accuracy score\n",
    "        best_train_score = score_train # save accuracy score for the training set for the validation set's best model\n",
    "\n",
    "print(\"Accuracy of the best model on the validation set (n_estimators = {}): {}\".format(best_est, best_score))\n",
    "print(\"Accuracy of the best model on the training set:\", best_train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is overfitted with a high training set accuracy score of 96.68% (much higher than the accuracy score of the validation set) and may run slowly with 6 estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Logistic Regression Model for the Validation Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the logistic regression model on the training set: 0.7505186721991701\n",
      "Accuracy of the logistic regression model on the validation set: 0.7402799377916018\n"
     ]
    }
   ],
   "source": [
    "# ititialize the Logistic Regression model\n",
    "model_lg =  LogisticRegression(\n",
    "    random_state=54321,\n",
    "    solver='liblinear'\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "model_lg.fit(train_features, train_target)  \n",
    "\n",
    "# score the model on the training data\n",
    "score_train = model_lg.score(train_features, train_target)\n",
    "\n",
    "# score the model on the validation data\n",
    "score_valid = model_lg.score(valid_features, valid_target)  \n",
    "\n",
    "# print the accuracy of the model on both the training and validation data sets\n",
    "print(\n",
    "    \"Accuracy of the logistic regression model on the training set:\",\n",
    "    score_train,\n",
    ")\n",
    "print(\n",
    "    \"Accuracy of the logistic regression model on the validation set:\",\n",
    "    score_valid,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is not overfitted and runs quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the accuracy score for the best Decision Tree Classifier model using the test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the best Decision Tree Classifier model (testing set): 0.7822706065318819\n"
     ]
    }
   ],
   "source": [
    "# check the accuracy of the best Descision Tree Classifier model on the test data set\n",
    "best_dt_model = DecisionTreeClassifier( # ititialize the Decision Tree Classifier Model\n",
    "        random_state=12345, \n",
    "        max_depth=7) \n",
    "\n",
    "# train the model\n",
    "best_dt_model.fit(train_features, train_target) \n",
    "\n",
    "# get the accuracy score of the model on the test data set\n",
    "test_result = best_dt_model.score(test_features, test_target) \n",
    "\n",
    "# print the accuracy score of the best Decision Tree Classifier model for the testing data set\n",
    "print(\"Accuracy of the best Decision Tree Classifier model (testing set):\", test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score of model using the testing data is lower than that using the validation data, but it's still the highest accuracy score at 78.22%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the accuracy score for the best Random Forest Classifier model using the test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best Random Forest Classifier model (testing set): 0.7573872472783826\n"
     ]
    }
   ],
   "source": [
    "# check the accuracy of the best Random Forest Classifier model on the test data set\n",
    "best_model_rf = RandomForestClassifier( # ititialize the Random Forest Classifier model\n",
    "        random_state=54321, \n",
    "        n_estimators=6 \n",
    "    ) \n",
    "\n",
    "# fit the model\n",
    "best_model_rf.fit(train_features, train_target)\n",
    "\n",
    "# get the accuracy score of the model on the test data set\n",
    "test_score = best_model_rf.score(test_features, test_target) # calculate accuracy score on validation set\n",
    "\n",
    "# print the accuracy score of the best Random Forest Classifier model for the testing data set\n",
    "print(\"Accuracy of the best Random Forest Classifier model (testing set):\", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score of model using the testing data is lower than that using the validation data by about 3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the accuracy score for the Logistic Regression model using the test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best Logistic Regression model (testing set): 0.7589424572317263\n"
     ]
    }
   ],
   "source": [
    "# check the accuracy of the Logistic Regression model on the test data set\n",
    "best_model_lg =  LogisticRegression(\n",
    "    random_state=54321,\n",
    "    solver='liblinear'\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "best_model_lg.fit(train_features, train_target)  \n",
    "\n",
    "# score the model on the training data\n",
    "score_test = best_model_lg.score(test_features, test_target)\n",
    "\n",
    "# print the accuracy score of the best Logistic Regression model for the testing data set\n",
    "print(\"Accuracy of the best Logistic Regression model (testing set):\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score of model using the testing data is slightly higher than that using the validation data, which is a solid result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check accuracy score: 0.693528313627878\n"
     ]
    }
   ],
   "source": [
    "# store df's features and target in variables\n",
    "features = df.drop(['is_ultra'], axis=1)\n",
    "target = df['is_ultra']\n",
    "\n",
    "# set predictions equal to the target median\n",
    "median_value = pd.Series(target.median(), index=target.index)\n",
    "\n",
    "# sanity check accuracy score of the target vs. the target median value\n",
    "sanity_check_result = accuracy_score(target, median_value) \n",
    "\n",
    "# print sanity check accuracy score\n",
    "print(\"Sanity check accuracy score:\", sanity_check_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score of the best model is higher than the accuracy score of simply using the median value of the target as the prediction. The best model (the Decision Tree Classifier model) works better than a simple approach to guessing the most common target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The decision tree classifier model is the best model overall with an accuracy score of 78.22%.\n",
    "\n",
    "The logistic regression model performed better than the random forest classifier model with an accuracy score of 75.89% vs. 75.73%, respectively. \n",
    "\n",
    "All three models beat our project's minimum accuracy score requirement of 75%."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 443,
    "start_time": "2024-06-12T17:11:19.833Z"
   },
   {
    "duration": 1081,
    "start_time": "2024-06-12T17:11:21.963Z"
   },
   {
    "duration": 34,
    "start_time": "2024-06-12T17:11:41.002Z"
   },
   {
    "duration": 21,
    "start_time": "2024-06-12T17:12:45.981Z"
   },
   {
    "duration": 20,
    "start_time": "2024-06-12T17:12:57.241Z"
   },
   {
    "duration": 30,
    "start_time": "2024-06-12T17:13:17.345Z"
   },
   {
    "duration": 7,
    "start_time": "2024-06-12T17:13:21.424Z"
   },
   {
    "duration": 5,
    "start_time": "2024-06-12T17:13:26.253Z"
   },
   {
    "duration": 6,
    "start_time": "2024-06-12T17:13:32.970Z"
   },
   {
    "duration": 20,
    "start_time": "2024-06-12T17:13:40.916Z"
   },
   {
    "duration": 22,
    "start_time": "2024-06-12T17:13:51.370Z"
   },
   {
    "duration": 28,
    "start_time": "2024-06-12T17:28:28.117Z"
   },
   {
    "duration": 779,
    "start_time": "2024-06-12T17:28:35.804Z"
   },
   {
    "duration": 23,
    "start_time": "2024-06-12T17:28:40.146Z"
   },
   {
    "duration": 13,
    "start_time": "2024-06-12T17:28:42.111Z"
   },
   {
    "duration": 4,
    "start_time": "2024-06-12T17:38:38.585Z"
   },
   {
    "duration": 104,
    "start_time": "2024-06-12T17:45:43.169Z"
   },
   {
    "duration": 45,
    "start_time": "2024-06-12T17:45:53.249Z"
   },
   {
    "duration": 24,
    "start_time": "2024-06-12T17:45:59.892Z"
   },
   {
    "duration": 63,
    "start_time": "2024-06-12T17:48:26.924Z"
   },
   {
    "duration": 57,
    "start_time": "2024-06-12T17:48:35.858Z"
   },
   {
    "duration": 88,
    "start_time": "2024-06-12T17:48:45.677Z"
   },
   {
    "duration": 1187,
    "start_time": "2024-06-12T17:49:56.383Z"
   },
   {
    "duration": 31,
    "start_time": "2024-06-12T17:49:57.575Z"
   },
   {
    "duration": 14,
    "start_time": "2024-06-12T17:49:57.612Z"
   },
   {
    "duration": 24,
    "start_time": "2024-06-12T17:49:57.631Z"
   },
   {
    "duration": 107,
    "start_time": "2024-06-12T17:49:57.659Z"
   },
   {
    "duration": 4,
    "start_time": "2024-06-12T17:49:57.769Z"
   },
   {
    "duration": 5,
    "start_time": "2024-06-12T17:49:57.776Z"
   },
   {
    "duration": 9,
    "start_time": "2024-06-12T17:51:54.089Z"
   },
   {
    "duration": 7,
    "start_time": "2024-06-12T17:52:04.117Z"
   },
   {
    "duration": 6,
    "start_time": "2024-06-12T17:52:11.166Z"
   },
   {
    "duration": 7,
    "start_time": "2024-06-12T17:52:24.086Z"
   },
   {
    "duration": 71,
    "start_time": "2024-06-12T17:52:31.020Z"
   },
   {
    "duration": 87,
    "start_time": "2024-06-12T17:53:44.851Z"
   },
   {
    "duration": 87,
    "start_time": "2024-06-12T17:54:42.509Z"
   },
   {
    "duration": 95,
    "start_time": "2024-06-12T17:56:03.234Z"
   },
   {
    "duration": 99,
    "start_time": "2024-06-12T17:56:22.776Z"
   },
   {
    "duration": 86,
    "start_time": "2024-06-12T17:56:33.232Z"
   },
   {
    "duration": 1241,
    "start_time": "2024-06-12T18:01:01.926Z"
   },
   {
    "duration": 26,
    "start_time": "2024-06-12T18:01:03.170Z"
   },
   {
    "duration": 18,
    "start_time": "2024-06-12T18:01:03.199Z"
   },
   {
    "duration": 105,
    "start_time": "2024-06-12T18:01:03.219Z"
   },
   {
    "duration": 4,
    "start_time": "2024-06-12T18:01:03.329Z"
   },
   {
    "duration": 4,
    "start_time": "2024-06-12T18:01:03.336Z"
   },
   {
    "duration": 207,
    "start_time": "2024-06-12T18:03:30.058Z"
   },
   {
    "duration": 4,
    "start_time": "2024-06-12T18:03:40.791Z"
   },
   {
    "duration": 23,
    "start_time": "2024-06-12T18:03:45.048Z"
   },
   {
    "duration": 4,
    "start_time": "2024-06-12T18:09:28.901Z"
   },
   {
    "duration": 314,
    "start_time": "2024-06-12T18:10:30.337Z"
   },
   {
    "duration": 27,
    "start_time": "2024-06-12T18:10:57.226Z"
   },
   {
    "duration": 8,
    "start_time": "2024-06-12T18:11:53.451Z"
   },
   {
    "duration": 27,
    "start_time": "2024-06-12T18:11:58.742Z"
   },
   {
    "duration": 27,
    "start_time": "2024-06-12T18:12:27.569Z"
   },
   {
    "duration": 1188,
    "start_time": "2024-06-12T18:12:42.377Z"
   },
   {
    "duration": 39,
    "start_time": "2024-06-12T18:12:43.568Z"
   },
   {
    "duration": 13,
    "start_time": "2024-06-12T18:12:43.609Z"
   },
   {
    "duration": 115,
    "start_time": "2024-06-12T18:12:43.626Z"
   },
   {
    "duration": 6,
    "start_time": "2024-06-12T18:12:43.744Z"
   },
   {
    "duration": 3,
    "start_time": "2024-06-12T18:12:43.753Z"
   },
   {
    "duration": 414,
    "start_time": "2024-06-12T18:18:17.005Z"
   },
   {
    "duration": 46,
    "start_time": "2024-06-12T18:18:37.191Z"
   },
   {
    "duration": 349,
    "start_time": "2024-06-12T18:18:50.278Z"
   },
   {
    "duration": 329,
    "start_time": "2024-06-12T18:23:35.923Z"
   },
   {
    "duration": 28,
    "start_time": "2024-06-12T18:26:29.001Z"
   },
   {
    "duration": 21,
    "start_time": "2024-06-12T18:26:43.506Z"
   },
   {
    "duration": 89,
    "start_time": "2024-06-12T18:29:53.938Z"
   },
   {
    "duration": 6,
    "start_time": "2024-06-12T18:34:46.461Z"
   },
   {
    "duration": 17,
    "start_time": "2024-06-12T18:34:53.319Z"
   },
   {
    "duration": 18,
    "start_time": "2024-06-12T18:37:20.930Z"
   },
   {
    "duration": 49,
    "start_time": "2024-06-12T18:39:50.544Z"
   },
   {
    "duration": 3,
    "start_time": "2024-06-12T18:48:07.740Z"
   },
   {
    "duration": 3,
    "start_time": "2024-06-12T18:48:09.726Z"
   },
   {
    "duration": 3,
    "start_time": "2024-06-12T18:48:32.654Z"
   },
   {
    "duration": 859,
    "start_time": "2024-06-12T19:02:55.662Z"
   },
   {
    "duration": 8,
    "start_time": "2024-06-12T19:03:10.810Z"
   },
   {
    "duration": 9,
    "start_time": "2024-06-12T19:03:41.649Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
