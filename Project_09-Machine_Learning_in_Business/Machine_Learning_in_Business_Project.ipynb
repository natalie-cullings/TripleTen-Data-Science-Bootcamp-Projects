{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Introduction\n",
    "\n",
    "As employees for the hypothetical oil mining company OilyGiant, our task is to find the best place for a new oil well.\n",
    "\n",
    "In order to choose the location, we must...\n",
    "- Collect the oil well parameters in the selected region: oil quality and volume of reserves.\n",
    "- Build a model for predicting the volume of reserves in the new wells.\n",
    "- Pick the oil wells with the highest estimated values.\n",
    "- Pick the region with the highest total profit for the selected oil wells.\n",
    "\n",
    "We have data on oil samples from three regions. Parameters of each oil well in the region are already known. Build a model that will help to pick the region with the highest profit margin. Analyze potential profit and risks using the Bootstrapping technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "Geological exploration data for the three regions are stored in files:\n",
    "- geo_data_0.csv\n",
    "- geo_data_1.csv\n",
    "- geo_data_2.csv\n",
    "\n",
    "Each dataset contains the following fields:\n",
    "- id — unique oil well identifier\n",
    "- f0, f1, f2 — three features of potential oil well points (their specific meaning is unimportant, but the features themselves are significant)\n",
    "- product — volume of reserves in the oil well (thousands of barrels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Conditions\n",
    "- Only linear regression is suitable for model training (other models are not sufficiently predictable).\n",
    "- When exploring the region, a study of 500 points is carried out; the best 200 points are picked for the profit calculation.\n",
    "- The budget for development of 200 oil wells is 100 USD million.\n",
    "- One barrel of raw materials brings in $4.5 USD of revenue. The revenue from one unit of product is $4,500 dollars (volume of reserves is in thousands of barrels).\n",
    "- After the risk evaluation, keep only the regions with the risk of losses lower than 2.5%. \n",
    "- From the ones that fit the criteria, the region with the highest average profit should be selected.\n",
    "\n",
    "The data is synthetic: contract details and well characteristics are not disclosed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Plan\n",
    "\n",
    "1. Import the necessary libraries for the project. \n",
    "2. Download and prepare the data.\n",
    "3. Designate the features and target for the model.\n",
    "4. Split the data into training and validation sets for each region.\n",
    "5. Scale the features for each model.\n",
    "5. Train the models and make predictions.\n",
    "6. Evaluate the models' RSME scores & compare them to the RSME score of each geo's mean target value.\n",
    "7. Prepare the data for the profit calculation.\n",
    "9. Calculate The profit for the best 200 well locations in each geo and recommend the best region for development.\n",
    "10. Calculate risks and profit for each region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import numpy as np\n",
    "from scipy import stats as st\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo 0 info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "\n",
      "geo 1 info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "\n",
      "geo 2 info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "\n",
      "geo 0 preview:       id        f0        f1        f2     product\n",
      "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
      "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
      "2  409Wp  1.022732  0.151990  1.419926   85.265647\n",
      "3  iJLyR -0.032172  0.139033  2.978566  168.620776\n",
      "4  Xdl7t  1.988431  0.155413  4.751769  154.036647\n",
      "\n",
      "geo 1 preview:       id         f0         f1        f2     product\n",
      "0  kBEdx -15.001348  -8.276000 -0.005876    3.179103\n",
      "1  62mP7  14.272088  -3.475083  0.999183   26.953261\n",
      "2  vyE1P   6.263187  -5.948386  5.001160  134.766305\n",
      "3  KcrkZ -13.081196 -11.506057  4.999415  137.945408\n",
      "4  AHL4O  12.702195  -8.147433  5.004363  134.766305\n",
      "\n",
      "geo 2 preview:       id        f0        f1        f2     product\n",
      "0  fwXo0 -1.146987  0.963328 -0.828965   27.758673\n",
      "1  WJtFt  0.262778  0.269839 -2.530187   56.069697\n",
      "2  ovLUW  0.194587  0.289035 -5.586433   62.871910\n",
      "3  q6cA6  2.236060 -0.553760  0.930038  114.572842\n",
      "4  WPMUX -0.515993  1.716266  5.899011  149.600746\n",
      "\n",
      "geo 0 number of duplicates: 0\n",
      "geo 1 number of duplicates: 0\n",
      "geo 2 number of duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# load the datasets into dataframes\n",
    "geo0 = pd.read_csv('geo_data_0.csv')\n",
    "geo1 = pd.read_csv('geo_data_1.csv')\n",
    "geo2 = pd.read_csv('geo_data_2.csv')\n",
    "\n",
    "# get info about each dataframe\n",
    "print(\"geo 0 info:\\n\")\n",
    "geo0.info()\n",
    "\n",
    "print(\"\\ngeo 1 info:\\n\")\n",
    "geo1.info()\n",
    "\n",
    "print(\"\\ngeo 2 info:\\n\")\n",
    "geo2.info()\n",
    "\n",
    "# preview each dataframe\n",
    "print(\"\\ngeo 0 preview:\", geo0.head())\n",
    "print(\"\\ngeo 1 preview:\", geo1.head())\n",
    "print(\"\\ngeo 2 preview:\", geo2.head())\n",
    "\n",
    "# check each dataframe for duplicate rows\n",
    "print(\"\\ngeo 0 number of duplicates:\", geo0.duplicated().sum())\n",
    "print(\"geo 1 number of duplicates:\", geo1.duplicated().sum())\n",
    "print(\"geo 2 number of duplicates:\", geo2.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data looks as expected with the correct data types. There are also no missing zeroes or duplicate rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designate the Features and Target for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the features in a separate dataframe for each region\n",
    "features_geo0 = geo0.drop(['product', 'id'], axis=1)\n",
    "features_geo1 = geo1.drop(['product', 'id'], axis=1)\n",
    "features_geo2 = geo2.drop(['product', 'id'], axis=1)\n",
    "\n",
    "# store the target in a separate series for each region\n",
    "target_geo0 = geo0['product'] \n",
    "target_geo1 = geo1['product']\n",
    "target_geo2 = geo2['product']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data into Training and Validation Sets for Each Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Split the features and target into training and validation sets for each region.\n",
    "''' \n",
    "\n",
    "# geo0\n",
    "features_train_geo0, features_valid_geo0, target_train_geo0, target_valid_geo0 = train_test_split(\n",
    "    features_geo0, target_geo0, test_size=0.25, random_state=12345)\n",
    "\n",
    "# geo1\n",
    "features_train_geo1, features_valid_geo1, target_train_geo1, target_valid_geo1 = train_test_split(\n",
    "    features_geo1, target_geo1, test_size=0.25, random_state=12345)\n",
    "\n",
    "# geo2\n",
    "features_train_geo2, features_valid_geo2, target_train_geo2, target_valid_geo2 = train_test_split(\n",
    "    features_geo2, target_geo2, test_size=0.25, random_state=12345)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each region, we made the validation set 25% of the original dataset size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Features for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "geo0\n",
    "'''\n",
    "\n",
    "# initialize the StandardScaler\n",
    "scaler_geo0 = StandardScaler()\n",
    "\n",
    "# train the scaler and transform the training features for geo0\n",
    "features_train_geo0 = scaler_geo0.fit_transform(features_train_geo0)\n",
    "features_valid_geo0 = scaler_geo0.transform(features_valid_geo0)\n",
    "\n",
    "'''\n",
    "geo1\n",
    "'''\n",
    "\n",
    "# initialize the StandardScaler\n",
    "scaler_geo1 = StandardScaler()\n",
    "\n",
    "# train the scaler and transform the training features for geo1\n",
    "features_train_geo1 = scaler_geo1.fit_transform(features_train_geo1)\n",
    "features_valid_geo1 = scaler_geo1.transform(features_valid_geo1)\n",
    "\n",
    "'''\n",
    "geo2\n",
    "'''\n",
    "\n",
    "# initialize the StandardScaler\n",
    "scaler_geo2 = StandardScaler()\n",
    "\n",
    "# train the scaler and transform the training features for geo2\n",
    "features_train_geo2 = scaler_geo2.fit_transform(features_train_geo2)\n",
    "features_valid_geo2 = scaler_geo2.transform(features_valid_geo2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model and Make Predictions for Each Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Geo0\n",
    "'''\n",
    "\n",
    "# initialize the model constructor\n",
    "model_geo0 = LinearRegression() \n",
    "\n",
    "# train the model on the training set\n",
    "model_geo0.fit(features_train_geo0, target_train_geo0) \n",
    "\n",
    "# get model predictions on the validation set\n",
    "predictions_valid_geo0 = model_geo0.predict(features_valid_geo0) \n",
    "\n",
    "'''\n",
    "Geo1\n",
    "'''\n",
    "\n",
    "# initialize the model constructor\n",
    "model_geo1 = LinearRegression() \n",
    "\n",
    "# train the model on the training set\n",
    "model_geo1.fit(features_train_geo1, target_train_geo1) \n",
    "\n",
    "# get model predictions on the validation set\n",
    "predictions_valid_geo1 = model_geo1.predict(features_valid_geo1) \n",
    "\n",
    "'''\n",
    "Geo2\n",
    "'''\n",
    "\n",
    "# initialize the model constructor\n",
    "model_geo2 = LinearRegression() \n",
    "\n",
    "# train the model on the training set\n",
    "model_geo2.fit(features_train_geo2, target_train_geo2) \n",
    "\n",
    "# get model predictions on the validation set\n",
    "predictions_valid_geo2 = model_geo2.predict(features_valid_geo2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "For each region, reset the index of the validation set target values dataframe and create a series of the validation set predictions with the same index.\n",
    "'''\n",
    "\n",
    "# geo0\n",
    "target_valid_geo0.reset_index(drop=True, inplace=True)\n",
    "predictions_valid_geo0 = pd.Series(predictions_valid_geo0, index=target_valid_geo0.index)\n",
    "\n",
    "# geo1\n",
    "target_valid_geo1.reset_index(drop=True, inplace=True)\n",
    "predictions_valid_geo1 = pd.Series(predictions_valid_geo1, index=target_valid_geo1.index)\n",
    "\n",
    "# geo2\n",
    "target_valid_geo2.reset_index(drop=True, inplace=True)\n",
    "predictions_valid_geo2 = pd.Series(predictions_valid_geo2, index=target_valid_geo2.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model's RSME score & Compare it to the RSME Score of the Mean Target Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the linear regression model on the validation set (geo0): 37.58\n",
      "RMSE of the linear regression model on the validation set (geo1): 0.89\n",
      "RMSE of the linear regression model on the validation set (geo2): 40.03\n",
      "\n",
      "Average value of the predictions for geo0: 92.59\n",
      "Average value of the predictions for geo1: 68.73\n",
      "Average value of the predictions for geo2: 94.97\n",
      "\n",
      "RMSE of comparing the mean of the target variable to the target variable (geo0): 44.29\n",
      "RMSE of comparing the mean of the target variable to the target variable (geo1): 45.94\n",
      "RMSE of comparing the mean of the target variable to the target variable (geo2: 44.75\n",
      "\n",
      "Max, min, and mean value of the target variable (geo0): 185.36 , 0.0 , 92.5\n",
      "Max, min, and mean value of the target variable (geo1): 137.95 , 0.0 , 68.83\n",
      "Max, min, and mean value of the target variable (geo2): 190.03 , 0.0 , 95.0\n"
     ]
    }
   ],
   "source": [
    "# calculate the RMSE of the models on the validation set and print them\n",
    "result_geo0 = mean_squared_error(target_valid_geo0, predictions_valid_geo0)**0.5\n",
    "print(\"RMSE of the linear regression model on the validation set (geo0):\", round(result_geo0,2))\n",
    "\n",
    "result_geo1 = mean_squared_error(target_valid_geo1, predictions_valid_geo1)**0.5\n",
    "print(\"RMSE of the linear regression model on the validation set (geo1):\", round(result_geo1,2))\n",
    "\n",
    "result_geo2 = mean_squared_error(target_valid_geo2, predictions_valid_geo2)**0.5\n",
    "print(\"RMSE of the linear regression model on the validation set (geo2):\", round(result_geo2,2))\n",
    "\n",
    "# print the average value of the predictions for each region\n",
    "print(\"\\nAverage value of the predictions for geo0:\", round(predictions_valid_geo0.mean(),2))\n",
    "print(\"Average value of the predictions for geo1:\", round(predictions_valid_geo1.mean(),2))\n",
    "print(\"Average value of the predictions for geo2:\", round(predictions_valid_geo2.mean(),2))\n",
    "\n",
    "# print the RSME of comparing the mean of the target variable to the target variable for each region\n",
    "print(\"\\nRMSE of comparing the mean of the target variable to the target variable (geo0):\",     round(root_mean_squared_error(target_geo0, pd.Series(target_geo0.mean(), index=target_geo0.index)), 2))\n",
    "print(\"RMSE of comparing the mean of the target variable to the target variable (geo1):\", round(root_mean_squared_error(target_geo1, pd.Series(target_geo1.mean(), index=target_geo1.index)),2))\n",
    "print(\"RMSE of comparing the mean of the target variable to the target variable (geo2:\", round(root_mean_squared_error(target_geo2, pd.Series(target_geo2.mean(), index=target_geo2.index)),2))\n",
    "\n",
    "\n",
    "# print the max, min, and mean values of the target variable for each region\n",
    "print(\"\\nMax, min, and mean value of the target variable (geo0):\", round(target_geo0.max(),2),\",\",target_geo0.min(),\",\",round(target_geo0.mean(),2))\n",
    "print(\"Max, min, and mean value of the target variable (geo1):\", round(target_geo1.max(),2),\",\", target_geo1.min(),\",\", round(target_geo1.mean(),2))\n",
    "print(\"Max, min, and mean value of the target variable (geo2):\", round(target_geo2.max(),2),\",\", target_geo2.min(),\",\", round(target_geo2.mean(),2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For geo0 and geo2, the RMSE value is around 20-21% of their respective targets' value range (min to max range). \n",
    "\n",
    "Geo1 has a very low RMSE score of about 0.89, which is great. \n",
    "\n",
    "We don't have a specific criteria about what our RSME score for our models must be, but the mean prediction value of each is very close to its respective mean (actual) target value, which is good.\n",
    "\n",
    "As a sanity check, we can also confirm that each model's RMSE score performs better than chance i.e. using the same answer (each model's actual target mean value) for each model's target predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data for the Profit Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Break-even point in product units per well: 111.11\n",
      "Break-even point in required profit per well (USD): 500000.00\n"
     ]
    }
   ],
   "source": [
    "# define the profit calculation inputs\n",
    "total_budget = 100000000\n",
    "number_of_wells = 200\n",
    "budget_per_well = total_budget / number_of_wells\n",
    "revenue_per_unit = 4500\n",
    "break_even_units = budget_per_well / revenue_per_unit\n",
    "\n",
    "print(f\"Break-even point in product units per well: {break_even_units:.2f}\")\n",
    "print(f\"Break-even point in required profit per well (USD): {budget_per_well:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a region to break-even on the production of 200 new oil wells, an average well would have to produce 111.11 units of product (each unit represents a thousand barrels).\n",
    "\n",
    "On average, regions 0, 1, and 2 produce 92.5, 68.8, and 95.0 units of product, respectively. Based on these averages alone, none of our regions would allow us to break even on our investment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate The Profit for the Top 200 Wells in Each Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit for the best 200 oil wells in geo0: 33208260.43\n",
      "Average profit per well in geo0: 166041.3\n",
      "\n",
      "Profit for the best 200 oil wells in geo1: 24150866.97\n",
      "Average profit per well in geo1: 120754.33\n",
      "\n",
      "Profit for the best 200 oil wells in geo2: 27103499.64\n",
      "Average profit per well in geo2: 135517.5\n"
     ]
    }
   ],
   "source": [
    "# define a function to calculate the profit for the best 200 oil wells in geo0\n",
    "def profit(target, predictions, count):\n",
    "    probs_sorted = predictions.sort_values(ascending=False) # sort the values of our predictions in descending order\n",
    "    selected = target[probs_sorted.index][:count] # select the target values with the top n predictions (n = count)\n",
    "    return (revenue_per_unit * selected.sum()) - total_budget # multiple the revenue (USD) per unit of product by the units produced by the top n wells then subtract the total budget (USD)\n",
    "\n",
    "# calculate the profit for the best 200 oil wells in geo0 and print the total profit and avg. profit per well\n",
    "profit_geo0 = profit(target_valid_geo0, predictions_valid_geo0, number_of_wells)\n",
    "print(f\"Profit for the best 200 oil wells in geo0: {round(profit_geo0,2)}\")\n",
    "print(f\"Average profit per well in geo0: {round((profit_geo0 / number_of_wells),2)}\")\n",
    "\n",
    "# calculate the profit for the best 200 oil wells in geo1 and print the total profit and avg. profit per well\n",
    "profit_geo1 = profit(target_valid_geo1, predictions_valid_geo1, number_of_wells)\n",
    "print(f\"\\nProfit for the best 200 oil wells in geo1: {round(profit_geo1,2)}\")\n",
    "print(f\"Average profit per well in geo1: {round((profit_geo1 / number_of_wells),2)}\")\n",
    "\n",
    "# calculate the profit for the best 200 oil wells in geo2 and print the total profit and avg. profit per well\n",
    "profit_geo2 = profit(target_valid_geo2, predictions_valid_geo2, number_of_wells)\n",
    "print(f\"\\nProfit for the best 200 oil wells in geo2: {round(profit_geo2,2)}\")\n",
    "print(f\"Average profit per well in geo2: {round((profit_geo2 / number_of_wells),2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geo0 is the most profitable overall with $33.2M in total profit and an average of $166.9K in profit per each of its top 200 wells (in terms of the wells that our model predicted would produce the most oil).\n",
    "\n",
    "Geo0 is about $9M (+27%) more profitable than geo1 and about $6.1M (+18.4%) more profitable than geo2 overall. Without yet taking our risk tolerance into account, geo0 is the clear choice for where we'd recommend the company to develop more oil wells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Risks and Profit for Each Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geo0:\n",
      "mean profit: 4259385.27\n",
      "95% confidence interval for the region: (4087322.0706869857, 4431448.467524861)\n",
      "Probability of a loss: 6.0%\n",
      "\n",
      "Geo1:\n",
      "mean profit: 5182594.94\n",
      "95% confidence interval for the region: (5052498.815766218, 5312691.058180281)\n",
      "Probability of a loss: 0.3%\n",
      "\n",
      "Geo2:\n",
      "mean profit: 4201940.05\n",
      "95% confidence interval for the region: (4025287.0365036144, 4378593.070377386)\n",
      "Probability of a loss: 6.2%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Use the bootstrapping technique to find the distribution of profit for each region.\n",
    "'''\n",
    "\n",
    "# set the RandomState value and store it in the variable \"state\"\n",
    "state = np.random.RandomState(12345)\n",
    "\n",
    "# set the number of bootstrap samples to 1000\n",
    "bootstrap_samples = 1000\n",
    "\n",
    "\n",
    "# def a function to generate bootstrap samples and calculate the samples' profit values, mean profit, 95% confidence interval for profit, and the probability of a loss\n",
    "def bootstrap_profit_ci_risk(target, predictions, num_samples, samp_size, num_wells, profit_values, alpha):\n",
    "    profit_values = [] # initiate an empty list to store the profit values\n",
    "    for i in range(num_samples): # iterate over the number of samples\n",
    "        target_subsample = target.sample(n=samp_size, replace=True, random_state=state) # generate a subsample of the target values\n",
    "        pred_subsample = predictions[target_subsample.index] # generate a subsample of the predictions\n",
    "    \n",
    "        profit_values.append(profit(target_subsample, pred_subsample, num_wells)) # calculate the profit for the subsample and append it to the profit_values list\n",
    "\n",
    "    profit_values = pd.Series(profit_values) # convert the profit_values list to a pandas series\n",
    "    \n",
    "    # designate the input values for the confidence interval calculation\n",
    "    alpha = alpha\n",
    "    df = len(profit_values) - 1\n",
    "    loc = profit_values.mean()\n",
    "    scale = profit_values.sem()\n",
    "\n",
    "    # calculate the 95% confidence interval for the profit_values list and format the output\n",
    "    confidence_interval = st.t.interval(alpha, df, loc, scale)\n",
    "    confidence_interval = (float(confidence_interval[0]), float(confidence_interval[1]))\n",
    "    \n",
    "    # calculate the probability of a loss\n",
    "    losses = profit_values[profit_values < 0]  # store profit values that are less than 0 in a separate series\n",
    "    number_of_losses = len(losses) # calculate the number of losses\n",
    "    total_samples = len(profit_values) # calculate the total number of samples\n",
    "    probability_of_loss = number_of_losses / total_samples # calculate the probability of a loss\n",
    "\n",
    "    # calculate the mean profit value\n",
    "    mean_profit = round(float(profit_values.mean()),2) # calculate the mean profit\n",
    "\n",
    "    # print the mean profit, 95% confidence interval for profit, and the probability of a loss\n",
    "    return print('mean profit:', mean_profit), print('95% confidence interval for the region:', confidence_interval), print(f'Probability of a loss: {probability_of_loss:.1%}')\n",
    "\n",
    "\n",
    "'''\n",
    "Run the bootstrap_profit_ci_risk function for geo0.\n",
    "'''\n",
    "\n",
    "# initiate an empty list of values\n",
    "values_geo0 = []\n",
    "\n",
    "# run the bootstrap_profit function for geo0\n",
    "print(\"Geo0:\")\n",
    "bootstrap_profit_ci_risk(target_valid_geo0, predictions_valid_geo0, bootstrap_samples, 500, 200, values_geo0, 0.95)\n",
    "\n",
    "'''\n",
    "Run the bootstrap_profit_ci_risk function for geo1.\n",
    "'''\n",
    "\n",
    "# initiate an empty list of values\n",
    "values_geo1 = []\n",
    "\n",
    "# run the bootstrap_profit function for geo1\n",
    "print(\"\\nGeo1:\")\n",
    "bootstrap_profit_ci_risk(target_valid_geo1, predictions_valid_geo1, bootstrap_samples, 500, 200, values_geo1, 0.95)\n",
    "\n",
    "'''\n",
    "Run the bootstrap_profit_ci_risk function for geo2.\n",
    "'''\n",
    "\n",
    "# initiate an empty list of values\n",
    "values_geo2 = []\n",
    "\n",
    "# run the bootstrap_profit function for geo2\n",
    "print(\"\\nGeo2:\")\n",
    "bootstrap_profit_ci_risk(target_valid_geo2, predictions_valid_geo2, bootstrap_samples, 500, 200, values_geo2, 0.95)\n",
    "\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geo1 is where we should develop new oil wells. It has the highest mean profit of $5.2M, the highest range of profit values for its 95% confidence interval range, and it's also the only region with less than a 2.5% probability of realizing a loss, which is our maximum tolerance for risk.\n",
    "\n",
    "To explore a region, the oil company studies 500 potential oil well locations and pick the best 200 to develop. The bootstrapping technique allowed us to simulate these studies by taking 1,000 samples of 500 potential oil sites, selecting the best 200 sites out of the 500 potential sites for each sample and, finally, calculating the profit each sample would generate.\n",
    "\n",
    "From there, we were able to calculate the average profitability of each region based on its 1,000 sample results, which gives us an average value that would be very close to the true population mean. We also were able to calculate the 95% confidence interval for the distribution of profit values that our 1,000 bootstrap samples gave us; this gives us confidence that, for geo1 as an example, we'd have a 95% probability of generating a range of profit from $5.05M to $5.31 in geo 1 no matter which 500 sites we decided to study and develop the top 200 sites within."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we relied on the linear regression models for each region alone, geo0 would have been the best region to develop new oil wells in with a total predicted profit of $33.2M in profit. \n",
    "\n",
    "However, the bootstraping technique allowed us to replicate the same conditions that the company employs when exporing a region i.e. developing the best 200 sites out of a given 500 potential sites that they study. Additionally, the bootstapping technique allowed us to make a recommendation that satisfied our maximum risk tolerance of 2.5% for realizing a loss. \n",
    "\n",
    "Ultimately, after applying the bootstrapping technique, geo1 was the only region that met our risk tolerance criteria. Fortunately, it also returned the highest average profit value of about $5.2M USD. With a 95% probability, we can feel confident that developing 200 new oil wells in geo1 will bring in a range of $5.05M to $5.31M USD and that there is only about a 0.3% probability of realizing a loss from the initiative. Notably, before we applied the bootstrapping technique, the geo1 region's linear regression model had the lowest RMSE value, which seems to align with its lowest risk of realizing a loss due to the lower variability of each site's production volume from the region's production volume mean in both actuality and in terms of our model's predicted production levels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
